{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Battle of the Neighborhoods (Austin Food Tour): </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Introduction/Business Problem:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px\">\tTravel and tourism is one of Texas’s biggest economic drivers, generating $80.2 billion in direct spending in 2018 [1]. People from all over the world flock to experience the unique culture and experience that the Lone Star State has to offer. Austin is one of the most tourist-friendly and famous cities in Texas. Austin hosts some of the most popular music festivals in the country like SXSW and the Austin City Limits Music Festival and is also home to the Circuit of The Americas. Because of the breadth of activities and experiences people can partake in, Austin draws in approximately 24.7 million domestic visitors each year [2].</p>\n",
    "\t<p style=\"font-size:18px\">Like many other cities, Austin is also home to some incredible restaurants. Tourists can indulge in unique cuisines all over the city and make their trip even more memorable. In this analysis, we are seeking to cluster the various neighborhoods in Austin by the types of restaurants they most frequently offer to understand what regions of Austin offer the most options of a specific type of cuisine. Then, we will be identifying the 5 most highly rated restaurants of the most popular cuisine for each cluster of neighborhoods in Austin to create a “must-go” restaurant list. </p>\n",
    "\t<p style=\"font-size:18px\">The stakeholders of this project are the city of Austin and its tourism board as this project will drive heavier tourist traffic around different areas of Austin. Travel bloggers, tourists, and college students will also benefit from this project as they can go to restaurants that are well-liked and experience cuisines that a particular neighborhood is known for. Restaurant owners have a great stake in this project as well because their restaurants may experience heavy foot-traffic because they were represented on this list. Restaurant owners who don’t rank as well may also use this listing and work to improve their rating.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px\"> The data required for this project will be collected via web-scraping and by using Foursquare’s API. Web-scraping will be used to create a pandas DataFrame of all of the neighborhoods available in Central Austin. We will then get the Latitude and Longitude values of the neighborhoods using the Nominatim package in python and add those values to our DataFrame. The final data we will be using is location data from Foursquare. We will be querying Foursquare’s API for data on what specific restaurants exist within Austin’s neighborhoods and how well they are rated. This information will be used for determining which cuisines are most popular in which neighborhoods and will allow us to cluster them according to similarity. We will then be able to complete our list of the 5 most highly rated restaurants in each cluster of neighborhoods.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1 Analysis</h3>\n",
    "<p style=\"font-size:18px\">\n",
    "To begin our analysis, we will be scraping Wikipedia for a list of all Neighborhoods in Central Austin. We will do this using the requests and BeautifulSoup libraries and then transport the information to a pandas dataframe. To do this, we are going to be importing all of the libraries we will need.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/envs/Python36/lib/python3.6/site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from beautifulsoup4) (1.7.1)\n",
      "Requirement already satisfied: lxml in /opt/conda/envs/Python36/lib/python3.6/site-packages (4.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (2.21.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests) (1.24.1)\n",
      "Requirement already satisfied: geocoder in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.38.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geocoder) (2.21.0)\n",
      "Requirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geocoder) (0.17.1)\n",
      "Requirement already satisfied: ratelim in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geocoder) (0.1.6)\n",
      "Requirement already satisfied: click in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geocoder) (7.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geocoder) (1.12.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->geocoder) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->geocoder) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->geocoder) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->geocoder) (2019.11.28)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ratelim->geocoder) (4.3.2)\n",
      "Requirement already satisfied: folium in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.10.1)\n",
      "Requirement already satisfied: branca>=0.3.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (0.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (2.21.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (2.10)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (1.15.4)\n",
      "Requirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from branca>=0.3.0->folium) (1.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (2.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from jinja2>=2.9->folium) (1.1.0)\n",
      "Packages fully loaded and installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install lxml\n",
    "!pip install requests\n",
    "!pip install geocoder\n",
    "!pip install folium\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geocoder\n",
    "import json \n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import folium\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "from geopy.geocoders import Nominatim \n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "print('Packages fully loaded and installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px\">Then, we will begin our web-scraping by defining the URL we will be using data from. We will go ahead and extract the data we need using the steps outlined below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bryker Woods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caswell Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downtown Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eastwoods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hancock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Heritage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hyde Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Judges' Hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lower Waller Creek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>North University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Oakmont Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Old Enfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Old Pecan Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Old West Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Original Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Original West University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pemberton Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ridgelea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ridgetop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rosedale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Shoal Crest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>West Downtown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0               Neighborhood\n",
       "1               Bryker Woods\n",
       "2            Caswell Heights\n",
       "3            Downtown Austin\n",
       "4                  Eastwoods\n",
       "5                    Hancock\n",
       "6                   Heritage\n",
       "7                  Hyde Park\n",
       "8               Judges' Hill\n",
       "9         Lower Waller Creek\n",
       "10          North University\n",
       "11           Oakmont Heights\n",
       "12               Old Enfield\n",
       "13          Old Pecan Street\n",
       "14           Old West Austin\n",
       "15           Original Austin\n",
       "16  Original West University\n",
       "17         Pemberton Heights\n",
       "18                  Ridgelea\n",
       "19                  Ridgetop\n",
       "20                  Rosedale\n",
       "21               Shoal Crest\n",
       "22             West Downtown"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define URL source\n",
    "source = requests.get('https://en.wikipedia.org/wiki/List_of_Austin_neighborhoods').text\n",
    "\n",
    "#create a Beautiful Soup object and define lxml as the parser\n",
    "soup= bsoup(source, 'lxml')\n",
    "\n",
    "#isolate the Austin Neighborhood names and add them to an empty list\n",
    "table= soup.find('table',class_ = 'wikitable')\n",
    "tabledata = table.tbody.text.split('\\n\\n')\n",
    "tabledata\n",
    "tableitems = []\n",
    "\n",
    "#append items to table data\n",
    "for rows in tabledata:\n",
    "    temp  = rows.split('\\n')[1:]\n",
    "    if (temp != []):\n",
    "        tableitems.append(temp[0])\n",
    "\n",
    "df=pd.DataFrame(tableitems)\n",
    "new_header = df.iloc[0]\n",
    "df = df[1:] \n",
    "df.columns = new_header\n",
    "df.rename(columns={'Name': \"Neighborhood\"}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px\">Next, use the Nominatim Package to add Latitude and Longitude coordinates to the DataFrame.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.7429861 -122.4158042\n"
     ]
    }
   ],
   "source": [
    "locator = Nominatim(user_agent = \"myagent\")\n",
    "location = locator.geocode('Bernal Heights, San Francisco, California')\n",
    "print(location.latitude, location.longitude)\n",
    "#judges hill, caswell heights, lower waller creek -> waller creek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bayview Hunters Point']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'latitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-26f5dff6ed3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighborhood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}, San Francisco, California'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighborhood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlatitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mlongitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'latitude'"
     ]
    }
   ],
   "source": [
    "#df['Major_Dist_Coord']= df['Major_District'].apply(locator.geocode).apply(lambda x: (x.latitude, x.longitude))\n",
    "\n",
    "#initialize your variable to None\n",
    "hello = newdf.values.tolist()\n",
    "for neighborhood in hello:\n",
    "    print(neighborhood)\n",
    "    g = locator.geocode('{}, San Francisco, California'.format(neighborhood))\n",
    "    latitude = g.latitude\n",
    "    longitude = g.longitude\n",
    "    print(latitude, longitude)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sources</h2>\n",
    "<ol style=\"font-size:18px\"> <li>https://www.bizjournals.com/austin/news/2019/05/02/tourisms-economic-impact-in-texas-164-billion.html</li>\n",
    "<li>https://www.austintexas.org/travel-professionals/</li></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NHOOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayview Hunters Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bernal Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castro/Upper Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chinatown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excelsior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   NHOOD\n",
       "0  Bayview Hunters Point\n",
       "1         Bernal Heights\n",
       "2    Castro/Upper Market\n",
       "3              Chinatown\n",
       "4              Excelsior"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf= pd.read_csv('https://data.sfgov.org/api/views/xfcw-9evu/rows.csv?accessType=DOWNLOAD')\n",
    "newdf.drop(['the_geom'], axis = 1, inplace=True)\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
