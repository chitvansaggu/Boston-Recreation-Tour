{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "<h1> Battle of the Neighborhoods (Austin Food Tour): </h1>"}, {"metadata": {}, "cell_type": "markdown", "source": "<h2> 1. Introduction/Business Problem:</h2>"}, {"metadata": {}, "cell_type": "markdown", "source": "<p style=\"font-size:18px\">\tTravel and tourism is one of Texas\u2019s biggest economic drivers, generating $80.2 billion in direct spending in 2018 [1]. People from all over the world flock to experience the unique culture and experience that the Lone Star State has to offer. Austin is one of the most tourist-friendly and famous cities in Texas. Austin hosts some of the most popular music festivals in the country like SXSW and the Austin City Limits Music Festival and is also home to the Circuit of The Americas. Because of the breadth of activities and experiences people can partake in, Austin draws in approximately 24.7 million domestic visitors each year [2].</p>\n\t<p style=\"font-size:18px\">Like many other cities, Austin is also home to some incredible restaurants. Tourists can indulge in unique cuisines all over the city and make their trip even more memorable. In this analysis, we are seeking to cluster the various neighborhoods in Austin by the types of restaurants they most frequently offer to understand what regions of Austin offer the most options of a specific type of cuisine. Then, we will be identifying the 5 most highly rated restaurants of the most popular cuisine for each cluster of neighborhoods in Austin to create a \u201cmust-go\u201d restaurant list. </p>\n\t<p style=\"font-size:18px\">The stakeholders of this project are the city of Austin and its tourism board as this project will drive heavier tourist traffic around different areas of Austin. Travel bloggers, tourists, and college students will also benefit from this project as they can go to restaurants that are well-liked and experience cuisines that a particular neighborhood is known for. Restaurant owners have a great stake in this project as well because their restaurants may experience heavy foot-traffic because they were represented on this list. Restaurant owners who don\u2019t rank as well may also use this listing and work to improve their rating.</p>"}, {"metadata": {}, "cell_type": "markdown", "source": "<h2>2. Data</h2>"}, {"metadata": {}, "cell_type": "markdown", "source": "<p style=\"font-size:18px\"> The data required for this project will be collected via web-scraping and by using Foursquare\u2019s API. Web-scraping will be used to create a pandas DataFrame of all of the neighborhoods available in Central Austin. We will then get the Latitude and Longitude values of the neighborhoods using the Nominatim package in python and add those values to our DataFrame. The final data we will be using is location data from Foursquare. We will be querying Foursquare\u2019s API for data on what specific restaurants exist within Austin\u2019s neighborhoods and how well they are rated. This information will be used for determining which cuisines are most popular in which neighborhoods and will allow us to cluster them according to similarity. We will then be able to complete our list of the 5 most highly rated restaurants in each cluster of neighborhoods.</p>"}, {"metadata": {}, "cell_type": "markdown", "source": "<h3>2.1 Analysis</h3>\n<p style=\"font-size:18px\">\nTo begin our analysis, we will be scraping Wikipedia for a list of all Neighborhoods in Central Austin. We will do this using the requests and BeautifulSoup libraries and then transport the information to a pandas dataframe. To do this, we are going to be importing all of the libraries we will need.</p>\n"}, {"metadata": {}, "cell_type": "code", "source": "!pip install beautifulsoup4\n!pip install lxml\n!pip install requests\n!pip install geocoder\n!pip install folium\n\nimport requests\nimport pandas as pd\nimport geocoder\nimport json \nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport folium\nimport numpy as np\nimport geopy\n\nfrom bs4 import BeautifulSoup as bsoup\nfrom geopy.geocoders import Nominatim \nfrom pandas.io.json import json_normalize\nfrom sklearn.cluster import KMeans\n\nprint('Packages fully loaded and installed.')", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: beautifulsoup4 in /opt/conda/envs/Python36/lib/python3.6/site-packages (4.7.1)\nRequirement already satisfied: soupsieve>=1.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from beautifulsoup4) (1.7.1)\nRequirement already satisfied: lxml in /opt/conda/envs/Python36/lib/python3.6/site-packages (4.3.1)\nRequirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (2.21.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests) (2019.11.28)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests) (1.24.1)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests) (3.0.4)\nRequirement already satisfied: geocoder in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.38.1)\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geocoder) (1.12.0)\nRequirement already satisfied: ratelim in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geocoder) (0.1.6)\nRequirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geocoder) (2.21.0)\nRequirement already satisfied: click in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geocoder) (7.0)\nRequirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geocoder) (0.17.1)\nRequirement already satisfied: decorator in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ratelim->geocoder) (4.3.2)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->geocoder) (3.0.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->geocoder) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->geocoder) (2019.11.28)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->geocoder) (1.24.1)\nRequirement already satisfied: folium in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.10.1)\nRequirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (2.21.0)\nRequirement already satisfied: jinja2>=2.9 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (2.10)\nRequirement already satisfied: branca>=0.3.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (0.3.1)\nRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (1.15.4)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (1.24.1)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (3.0.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (2019.11.28)\nRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from jinja2>=2.9->folium) (1.1.0)\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from branca>=0.3.0->folium) (1.12.0)\nPackages fully loaded and installed.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<p style=\"font-size:18px\">Then, we will begin our web-scraping by defining the URL we will be using data from. We will go ahead and extract the data we need using the steps outlined below.</p>"}, {"metadata": {}, "cell_type": "code", "source": "#define URL source\nsource = requests.get('https://en.wikipedia.org/wiki/List_of_Austin_neighborhoods').text\n\n#create a Beautiful Soup object and define lxml as the parser\nsoup= bsoup(source, 'lxml')\n\n#isolate the Austin Neighborhood names and add them to an empty list\ntable= soup.find('table',class_ = 'wikitable')\ntabledata = table.tbody.text.split('\\n\\n')\ntabledata\ntableitems = []\n\n#append items to table data\nfor rows in tabledata:\n    temp  = rows.split('\\n')[1:]\n    if (temp != []):\n        tableitems.append(temp[0])\n\ndf=pd.DataFrame(tableitems)\nnew_header = df.iloc[0]\ndf = df[1:] \ndf.columns = new_header\ndf.rename(columns={'Name': \"Neighborhood\"}, inplace=True)\ndf", "execution_count": 2, "outputs": [{"output_type": "execute_result", "execution_count": 2, "data": {"text/plain": "0               Neighborhood\n1               Bryker Woods\n2            Caswell Heights\n3            Downtown Austin\n4                  Eastwoods\n5                    Hancock\n6                   Heritage\n7                  Hyde Park\n8               Judges' Hill\n9         Lower Waller Creek\n10          North University\n11           Oakmont Heights\n12               Old Enfield\n13          Old Pecan Street\n14           Old West Austin\n15           Original Austin\n16  Original West University\n17         Pemberton Heights\n18                  Ridgelea\n19                  Ridgetop\n20                  Rosedale\n21               Shoal Crest\n22             West Downtown", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Neighborhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Bryker Woods</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Caswell Heights</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Downtown Austin</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Eastwoods</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Hancock</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Heritage</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Hyde Park</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Judges' Hill</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Lower Waller Creek</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>North University</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Oakmont Heights</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Old Enfield</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Old Pecan Street</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Old West Austin</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Original Austin</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Original West University</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Pemberton Heights</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Ridgelea</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Ridgetop</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Rosedale</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Shoal Crest</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>West Downtown</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "<p style=\"font-size:18px\">Next, use the Nominatim Package to check Latitude and Longitude coordinates to the DataFrame.</p>\n"}, {"metadata": {}, "cell_type": "code", "source": "from geopy.exc import GeocoderTimedOut\nlocator = Nominatim(user_agent = \"austinagent\")\ndef do_geocode(address):\n    try:\n        return locator.geocode(address)\n    except GeocoderTimedOut:\n        return do_geocode(address)", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "neighborhoods = df.values.tolist()\ncoordinates = []\nfor neighborhood in neighborhoods:\n    print(neighborhood)\n    g = do_geocode('{}, Austin, Texas'.format(neighborhood))\n    if (g == None):\n        coordinates.append('None')\n    else:\n        coordinates.append(str(g.latitude) + ', ' + str(g.longitude))\n\ncoordinates", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "['Bryker Woods']\n['Caswell Heights']\n['Downtown Austin']\n['Eastwoods']\n['Hancock']\n['Heritage']\n['Hyde Park']\n[\"Judges' Hill\"]\n['Lower Waller Creek']\n['North University']\n['Oakmont Heights']\n['Old Enfield']\n['Old Pecan Street']\n['Old West Austin']\n['Original Austin']\n['Original West University']\n['Pemberton Heights']\n['Ridgelea']\n['Ridgetop']\n['Rosedale']\n['Shoal Crest']\n['West Downtown']\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 14, "data": {"text/plain": "['30.305246, -97.7545846',\n 'None',\n '30.2680536, -97.7447642',\n '30.290562350000002, -97.73141774152433',\n '30.2958956, -97.7247678',\n '30.3457961, -97.6909909',\n '30.3044117, -97.7304485',\n 'None',\n 'None',\n '30.42100665, -97.84008580625134',\n '30.3119891, -97.7540697',\n '30.2848643, -97.7591064',\n '29.8905618, -96.4887858',\n '30.296822, -97.7548514',\n '30.2737783, -97.72048',\n 'None',\n '30.1900716, -97.83857107484684',\n '30.3115548, -97.7513953',\n '30.311527050000002, -97.71641825831956',\n '30.3133901, -97.7448982',\n '30.2974652, -97.7478879',\n '30.2680536, -97.7447642']"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "<p style=\"font-size:18px\">As you can see, some neighborhoods in our DataFrame are returning 'None' when Nominatim tries to find the coordinates for these locations. After further investigation, we found that Nominatim does not have coordinates for these neighborhoods, as shown in the screenshot below. For the purposes of this exercise, we will be either dropping or renaming the rows which do not have coordinates in Nominatim. The Neighborhoods that do not have coordinates are \"Caswell Heights\", \"Judges' Hill\", \"Lower Waller Creek\", and \"Original West University\". Nominatim does not have data on a \"Lower Waller Creek\", but it does have data on \"Waller Creek\".</p>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "<h2>Sources</h2>\n<ol style=\"font-size:18px\"> <li>https://www.bizjournals.com/austin/news/2019/05/02/tourisms-economic-impact-in-texas-164-billion.html</li>\n<li>https://www.austintexas.org/travel-professionals/</li></ol>"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}